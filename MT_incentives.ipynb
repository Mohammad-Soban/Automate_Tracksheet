{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python_3.10.2\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.0\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlwt in c:\\python_3.10.2\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlwt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwt\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Excel file\n",
    "original_excel_file = \"./Tracksheet/May_2024.xls\"\n",
    "\n",
    "# Path to your new Excel file\n",
    "new_excel_file = './Tracksheet/May_Middle.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(original_excel_file, sheet_name=None)\n",
    "all_sheets = pd.read_excel(original_excel_file, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check wheteher every sheet is read or not\n",
    "# # Print columns for each sheet\n",
    "# for sheet_name, df in all_sheets.items():\n",
    "#     print(f\"Sheet: {sheet_name}\")\n",
    "\n",
    "# # Print the first 5 rows for each sheet\n",
    "# for sheet_name, df in all_sheets.items():\n",
    "#     print(f\"Sheet: {sheet_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the rows in the dataframe which contains np.nan in the column \"Transcribed By\"\n",
    "for sheet_name, df in all_sheets.items():\n",
    "    # Check if 'Transcribed By' column exists in the DataFrame\n",
    "    if 'Transcribed By' in df.columns:\n",
    "        df.dropna(subset=['Transcribed By'], inplace=True)\n",
    "    else:\n",
    "        print(f\"Skipping sheet '{sheet_name}' due to missing 'Transcribed By' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RM/TA', 'SV', 'RM', 'KP', 'PS', 'TA', 'HS'}\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique values in the Transcribed By column from every sheet and store them in a set which contains the unique values from all the sheets\n",
    "unique_values = set()\n",
    "for sheet_name, df in all_sheets.items():\n",
    "    if 'Transcribed By' in df.columns:\n",
    "        unique_values.update(df['Transcribed By'].unique())\n",
    "    else:\n",
    "        print(f\"Skipping sheet '{sheet_name}' due to missing 'Transcribed By' column.\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SV', 'RM', 'KP', 'PS', 'TA', 'HS'}\n"
     ]
    }
   ],
   "source": [
    "# Create a new empty set and store the first 2 characters of each unique value in the Transcribed By column from every sheet\n",
    "unique_values_2 = set()\n",
    "\n",
    "try: \n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        unique_values_2.update(df['Transcribed By'].str[:2].unique())\n",
    "    print(unique_values_2)\n",
    "\n",
    "except AttributeError:\n",
    "    print(f\"Error occured in {sheet_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"VoiceFile Name\", \"Document Name\", \"DOB\", \"Doctor\", \"Date on FTP\", \"Download Date\", \"DOS\", \"Transcribe Date\", \"Transcribed By\", \"Line Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammad Soban\\AppData\\Local\\Temp\\ipykernel_9076\\3515106496.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix)])\n",
      "C:\\Users\\Mohammad Soban\\AppData\\Local\\Temp\\ipykernel_9076\\3515106496.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix)])\n",
      "C:\\Users\\Mohammad Soban\\AppData\\Local\\Temp\\ipykernel_9076\\3515106496.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix)])\n",
      "C:\\Users\\Mohammad Soban\\AppData\\Local\\Temp\\ipykernel_9076\\3515106496.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix)])\n"
     ]
    }
   ],
   "source": [
    "# Assuming all_sheets and unique_values_2 are defined\n",
    "created_sheets = set()\n",
    "\n",
    "with pd.ExcelWriter(new_excel_file, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        \n",
    "        # Check if 'Transcribed By' column exists in the DataFrame\n",
    "        if 'Transcribed By' in df.columns:\n",
    "            for value in unique_values_2:\n",
    "                # Ensure that 'Transcribed By' values are strings\n",
    "                df['Transcribed By'] = df['Transcribed By'].astype(str)\n",
    "\n",
    "                # Filter rows based on string values in 'Transcribed By' column\n",
    "                filtered_rows = df[df['Transcribed By'].str.startswith(value)]\n",
    "                sheet_name_to_create = f'{sheet_name}_{value}'\n",
    "                filtered_rows.to_excel(writer, sheet_name=sheet_name_to_create, index=False)\n",
    "                created_sheets.add(sheet_name_to_create)\n",
    "        else:\n",
    "            print(f\"Skipping sheet '{sheet_name}' due to missing 'Transcribed By' column.\")\n",
    "\n",
    "# Create a new workbook for merging similar sheets\n",
    "merged_excel_file = './Tracksheet/May_MT_Incentives.xls'\n",
    "with pd.ExcelWriter(merged_excel_file, engine='openpyxl') as writer:\n",
    "    for suffix in set(sheet_name[-2:] for sheet_name in created_sheets):\n",
    "        # Concatenate only the specified columns\n",
    "        merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix)])\n",
    "\n",
    "        # Format date columns\n",
    "        for date_column in [\"DOB\", \"Date on FTP\", \"Download Date\", \"DOS\", \"Transcribe Date\"]:\n",
    "            merged_df[date_column] = pd.to_datetime(merged_df[date_column], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "\n",
    "        # Calculate the total line count\n",
    "        total_line_count = merged_df[\"Line Count\"].sum()\n",
    "\n",
    "        # Create a new DataFrame for the total line count\n",
    "        total_row = pd.DataFrame({\"Line Count\": [total_line_count]})\n",
    "\n",
    "        # Concatenate the total row with the merged DataFrame\n",
    "        merged_df = pd.concat([merged_df, total_row])\n",
    "\n",
    "        # Write the DataFrame to the Excel file\n",
    "        merged_df.to_excel(writer, sheet_name=suffix, index=False, header=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'Workbook' object has no attribute 'create_sheet'\n"
     ]
    }
   ],
   "source": [
    "# Assuming all_sheets and unique_values_2 are defined\n",
    "created_sheets = set()\n",
    "\n",
    "try:\n",
    "    # Create new Excel file with a default sheet\n",
    "    new_excel_file = './March/March_MT_incentives_Filtered.xlsx'\n",
    "    with pd.ExcelWriter(new_excel_file, engine='xlsxwriter') as writer:\n",
    "        # Create a default sheet to ensure at least one sheet is visible\n",
    "        writer.book.create_sheet(title='Sheet1')\n",
    "\n",
    "        for sheet_name, df in all_sheets.items():\n",
    "            # Check if 'Transcribed By' column exists in the DataFrame\n",
    "            if 'Transcribed By' in df.columns:\n",
    "                for value in unique_values_2:\n",
    "                    # Ensure that 'Transcribed By' values are strings\n",
    "                    df['Transcribed By'] = df['Transcribed By'].astype(str)\n",
    "\n",
    "                    # Filter rows based on string values in 'Transcribed By' column\n",
    "                    filtered_rows = df[df['Transcribed By'].str.startswith(value)]\n",
    "                    sheet_name_to_create = f'{sheet_name}_{value}'\n",
    "                    filtered_rows.to_excel(writer, sheet_name=sheet_name_to_create, index=False)\n",
    "                    created_sheets.add(sheet_name_to_create)\n",
    "            else:\n",
    "                print(f\"Skipping sheet '{sheet_name}' due to missing 'Transcribed By' column.\")\n",
    "\n",
    "    # Create a new workbook for merging similar sheets\n",
    "    merged_excel_file = './March/March_MT_incentives_Merged.xlsx'\n",
    "    with pd.ExcelWriter(merged_excel_file, engine='xlsxwriter') as writer:\n",
    "        for suffix in set(sheet_name[-2:] for sheet_name in created_sheets):\n",
    "            # Concatenate only the specified columns from all sheets\n",
    "            merged_df = pd.concat([pd.read_excel(new_excel_file, sheet_name=sheet_name)[columns] for sheet_name in created_sheets if sheet_name.endswith(suffix) and not pd.read_excel(new_excel_file, sheet_name=sheet_name).empty])\n",
    "\n",
    "            # Format date columns\n",
    "            for date_column in [\"DOB\", \"Date on FTP\", \"Download Date\", \"DOS\", \"Transcribe Date\"]:\n",
    "                merged_df[date_column] = pd.to_datetime(merged_df[date_column], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "\n",
    "            # Calculate and append the total sum of Line Count\n",
    "            total_line_count = merged_df[\"Line Count\"].sum()\n",
    "            merged_df = merged_df.append({\"Line Count\": total_line_count}, ignore_index=True)\n",
    "\n",
    "            # Write column headers and formatted date columns\n",
    "            merged_df.to_excel(writer, sheet_name=suffix, index=False, header=columns)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
